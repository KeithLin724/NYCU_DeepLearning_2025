{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f2d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "# https://medium.com/willhanchen/%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86-spacy-%E5%88%9D%E6%8E%A2%E5%BC%B7%E5%A4%A7%E7%9A%84%E5%B7%A5%E5%85%B7%E5%BA%ABspacy-%E8%AE%93%E6%A9%9F%E5%99%A8%E8%AE%80%E6%87%82%E6%88%91%E5%80%91%E7%9A%84%E8%AA%9E%E8%A8%80%E5%90%A7-4a35daa895d0\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import FastText, word2vec, Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# for model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import math\n",
    "from natsort import natsorted\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split   \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638b28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILD_TEXT_DATA = False \n",
    "LOAD_TEXT_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d15db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH config\n",
    "ALL_OUTPUT_PATH = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157b98e",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8adc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextData:\n",
    "    # embedding model use fasttext\n",
    "    def __init__(self, train_data:pd.DataFrame, test_data:pd.DataFrame):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.embedding_model_name = None\n",
    "        \n",
    "        self.setup()\n",
    "        return \n",
    "    \n",
    "    def train_embedding_model(self, result_files:dict, model_type:str=\"skipgram\", embedding_size:int=100):\n",
    "        self.embedding_model_name = model_type\n",
    "        data_folder = Path(result_files[\"folder\"])\n",
    "        file_to_train = data_folder / result_files[\"embedding_training\"]\n",
    "        \n",
    "        sentences = word2vec.LineSentence(file_to_train)\n",
    "        \n",
    "        self.model = FastText(\n",
    "            sentences,\n",
    "            vector_size=embedding_size,\n",
    "            window=5,\n",
    "            min_count=1,\n",
    "            sg=1 if model_type == \"skipgram\" else 0, # skipgram = 1, cbow = 0\n",
    "            hs=0,\n",
    "            negative=5,\n",
    "            epochs=10,\n",
    "        )\n",
    "        \n",
    "        model_folder = Path(\"model\")\n",
    "        model_folder.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        model_file_name =  f\"{model_type}.model\"\n",
    "        self.model.save(str(model_folder / model_file_name))\n",
    "        \n",
    "        return {\"model_folder\": str(model_folder), \"model_file_name\":model_file_name, \"model_type\": model_type}\n",
    "    \n",
    "    def load_embedding_model(self, model_path:str):\n",
    "        self.embedding_model_name = model_path\n",
    "        self.model = FastText.load(model_path)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def setup(self):\n",
    "        # 第一次執行需要下載停用詞資源\n",
    "        nltk.download(\"stopwords\")\n",
    "        download(\"en_core_web_sm\")\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        return\n",
    "    \n",
    "    def clean_text_spacy(self, text:str) -> str:\n",
    "        condition = lambda token : not token.is_stop and not token.is_punct and not token.is_digit\n",
    "        \n",
    "        doc = self.nlp(text)\n",
    "        # 篩選出非停用字、非標點符號、非數字的 token，並轉為小寫\n",
    "        tokens = [token.text.lower() for token in doc if condition(token)]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    def clean_text_nltk(self, text: str) -> str:\n",
    "        # 轉成小寫\n",
    "        text = text.lower()\n",
    "        # 移除數字\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # 移除標點符號\n",
    "        text = re.sub(r'[{}]'.format(re.escape(string.punctuation)), '', text)\n",
    "        # 移除多餘空白\n",
    "        text = text.strip()\n",
    "        # 斷詞\n",
    "        tokens = text.split()\n",
    "        # 移除停用字\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # 回傳清理後的結果\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    def batch_process_text(self, process_funcs:list[Callable], max_workers:int=None):\n",
    "        result = []\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [executor.submit(process_func) for process_func in process_funcs]\n",
    "            for future in as_completed(futures):\n",
    "                result.append(future.result())\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    def wrapper_function(self,id_:int, type_:int, headline_in:str, short_description_in:str, label:int, process_func:str):\n",
    "        \n",
    "        def process_it():\n",
    "            headline = process_func(headline_in)\n",
    "            short_description = process_func(short_description_in)\n",
    "            item = \"<CLS> \" + headline + \" <SEP> \" +  short_description + \" <END>\"\n",
    "            return {\"id\": id_, \"type\": type_, \"process_text\": item, \"label\": label}\n",
    "        \n",
    "        return process_it\n",
    "    \n",
    "    \n",
    "    def process_all_data(self, process:str, batch_size:int=100, max_workers:int=None):\n",
    "        process_func = self.clean_text_spacy if process == \"spacy\" else self.clean_text_nltk\n",
    "        \n",
    "        train_data_df = self.train_data[[\"id\" , \"headline\", \"short_description\", \"label\"]].copy()\n",
    "        train_data_df[\"type\"] = \"train\"\n",
    "        test_data_df = self.test_data[[\"id\" ,\"headline\", \"short_description\"]].copy()\n",
    "        test_data_df[\"type\"] = \"test\"\n",
    "        test_data_df[\"label\"] = \"IDK\"\n",
    "        \n",
    "        data_df = pd.concat([train_data_df, test_data_df], axis=0)\n",
    "        \n",
    "        \n",
    "        jobs = []\n",
    "        for _, row in tqdm(data_df.iterrows(), total=data_df.shape[0], desc=\"Build Jobs\"):\n",
    "            id_ = row[\"id\"]\n",
    "            type_ = row[\"type\"]\n",
    "            headline = row[\"headline\"]\n",
    "            short_description = row[\"short_description\"]\n",
    "            label = row[\"label\"]\n",
    "            \n",
    "            # 使用 wrapper_function 來包裝 process_func\n",
    "            job = self.wrapper_function(id_, type_, headline, short_description, label , process_func)\n",
    "            jobs.append(job)\n",
    "        \n",
    "        result = []\n",
    "        for batch in tqdm(range(0, len(jobs), batch_size), desc=\"Processing text\"):\n",
    "            batch_jobs = jobs[batch:batch + batch_size]\n",
    "            out = self.batch_process_text(batch_jobs, max_workers)\n",
    "            result.extend(out)\n",
    "        \n",
    "        \n",
    "        output_df = pd.DataFrame(result)\n",
    "        \n",
    "        folder = Path(\"temp\")\n",
    "        folder.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        prefix = f\"temp_{process}\"\n",
    "        \n",
    "        # to temp file for embedding\n",
    "        with open(folder / f\"{prefix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            # add special tokens\n",
    "            f.write(\"<PAD> <CLS> <SEP> <END> <UNK>\\n\")\n",
    "            for text in output_df[\"process_text\"]:\n",
    "                f.write(text + \"\\n\")\n",
    "        \n",
    "        # save processed data\n",
    "        output_df.to_csv(folder / f\"{prefix}.csv\", index=False)\n",
    "        \n",
    "        output_dict = {\"folder\":str(folder), \"embedding_training\" :f\"{prefix}.txt\", \"record\": f\"{prefix}.csv\" }\n",
    "        # split train test data\n",
    "        train_test_path = TextData.split_train_test_data(output_dict)\n",
    "        \n",
    "        return output_dict | train_test_path\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_train_test_data(process_all_data_output:dict):\n",
    "        \n",
    "        folder = process_all_data_output[\"folder\"]\n",
    "        folder = Path(folder) \n",
    "        record_file = process_all_data_output[\"record\"]\n",
    "        record_path = folder / record_file\n",
    "        df = pd.read_csv(record_path, low_memory=False, dtype={\"process_text\": str})\n",
    "        \n",
    "        df_train = df[df[\"type\"] == \"train\"].copy()\n",
    "        df_test = df[df[\"type\"] == \"test\"].copy()\n",
    "        \n",
    "        df_train = df_train.sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        df_test = df_test.sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        \n",
    "        df_train = df_train.drop(columns=[\"type\"])\n",
    "        df_test = df_test.drop(columns=[\"type\"])\n",
    "        \n",
    "        prefix = record_file.replace(\".csv\", \"\")    \n",
    "        \n",
    "        train_file = folder / f\"{prefix}_train.csv\"\n",
    "        test_file = folder / f\"{prefix}_test.csv\"\n",
    "        \n",
    "        df_train.to_csv(train_file, index=False)\n",
    "        df_test.to_csv(test_file, index=False)\n",
    "        return {\"train_path\": str(train_file), \"test_path\": str(test_file)}\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_from_folder(folder:str): \n",
    "        path = Path(folder)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Folder {folder} does not exist.\")\n",
    "        \n",
    "        train_data_json = path / \"News_train.json\"\n",
    "        test_data_json = path / \"News_test.json\"\n",
    "        \n",
    "        with open(train_data_json, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            train_data = [json.loads(line) for line in lines]   \n",
    "            \n",
    "        with open(test_data_json, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            test_data = [json.loads(line) for line in lines]\n",
    "        \n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "        \n",
    "        return TextData(train_data, test_data)\n",
    "    \n",
    "    \n",
    "    def tokenize(self, text:str | list[str]) -> np.ndarray:\n",
    "        # 使用 FastText 模型進行斷詞\n",
    "        unk_id = self.model.wv.key_to_index.get(\"<UNK>\", 0)\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            text_ls = text.split()\n",
    "        elif isinstance(text, list):\n",
    "            text_ls = text\n",
    "\n",
    "        token_nums = [\n",
    "            self.model.wv.key_to_index.get(text, unk_id)\n",
    "            for text in text_ls\n",
    "        ]\n",
    "        \n",
    "        return token_nums\n",
    "    \n",
    "    \n",
    "    def embedding_data(self):\n",
    "        vocab = self.model.wv.index_to_key\n",
    "        vocab_size = len(vocab)\n",
    "        embed_dim = self.model.wv.vector_size\n",
    "        embedding_weight = torch.FloatTensor(\n",
    "            np.array([self.model.wv[word] for word in vocab])\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"vocab\": vocab,\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"embedding_weight\": embedding_weight\n",
    "        }\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_cross_entry_weights(folder_counts:dict) -> list[float]:\n",
    "        total_samples = sum(folder_counts.values())\n",
    "        num_classes = len(folder_counts)\n",
    "        class_weights = {\n",
    "            class_id: total_samples / (num_classes * count) \n",
    "            for class_id, count in folder_counts.items()\n",
    "        }\n",
    "\n",
    "        class_weights = {\n",
    "            k: v for k, v in sorted(class_weights.items(), key=lambda item: item[0])\n",
    "        }\n",
    "        \n",
    "        # 將權重轉換為 tensor 並標準化\n",
    "        weights = torch.tensor(list(class_weights.values()), dtype=torch.float)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        return weights.tolist()\n",
    "    \n",
    "    def ce_weights(self):\n",
    "        return self.get_cross_entry_weights(self.train_data[\"label\"].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54d3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./2025-deep-learning-hw-2-text-classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb793da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/keithlin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "text_data = TextData.load_from_folder(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da919086",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESS_TYPE = \"spacy\"\n",
    "PROCESS_DATA_BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16a8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUILD_TEXT_DATA:\n",
    "    output = text_data.process_all_data(PROCESS_TYPE, batch_size=PROCESS_DATA_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9483bc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'folder': 'temp', 'embedding_training': 'temp_spacy.txt', 'record': 'temp_spacy.csv', 'train_path': 'temp_spacy_train.csv', 'test_path': 'temp_spacy_test.csv'}\n"
     ]
    }
   ],
   "source": [
    "if LOAD_TEXT_DATA:\n",
    "    folder = Path(\"temp\")\n",
    "    folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    prefix = f\"temp_{PROCESS_TYPE}\"\n",
    "    output = {\n",
    "        \"folder\":str(folder), \n",
    "        \"embedding_training\" :f\"{prefix}.txt\", \n",
    "        \"record\": f\"{prefix}.csv\",\n",
    "        \"train_path\":f\"{prefix}_train.csv\", \n",
    "        \"test_path\": f\"{prefix}_test.csv\" \n",
    "    }\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e1a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_METHOD = \"skipgram\"\n",
    "EMBEDDING_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babd3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUILD_TEXT_DATA:\n",
    "    model_file = text_data.train_embedding_model(output, model_type=EMBEDDING_METHOD, embedding_size=EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24d4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_TEXT_DATA:\n",
    "    model_file = {\"model_folder\": \"model\", \"model_file_name\":f\"{EMBEDDING_METHOD}.model\", \"model_type\": EMBEDDING_METHOD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9086040",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_PATH = Path(model_file[\"model_folder\"]) / model_file[\"model_file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6648623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_TEXT_DATA:\n",
    "    text_data.load_embedding_model(str(EMBEDDING_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227fc6c8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995f6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet(Dataset):\n",
    "    def __init__(self, df_in:pd.DataFrame, key_to_index:dict, for_test:bool=False):\n",
    "        super().__init__()\n",
    "        self.key_to_index = key_to_index\n",
    "        self.data = df_in\n",
    "        \n",
    "        self.labels = natsorted(set(df_in[\"label\"].values))\n",
    "        self.for_test = for_test\n",
    "        return\n",
    "    \n",
    "    def detokenize(self, token_nums:list[int]) -> str:\n",
    "        # 使用 FastText 模型進行斷詞\n",
    "        index_to_key = list(self.key_to_index.keys())\n",
    "        text = \" \".join([\n",
    "            index_to_key[token_num]\n",
    "            for token_num in token_nums\n",
    "        ])\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize(self, text:str | list[str]) -> np.ndarray:\n",
    "        # 使用 FastText 模型進行斷詞\n",
    "        unk_id = self.key_to_index.get(\"<UNK>\", 0)\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            text_ls = text.split()\n",
    "        elif isinstance(text, list):\n",
    "            text_ls = text\n",
    "\n",
    "        token_nums = [\n",
    "            self.key_to_index.get(text, unk_id)\n",
    "            for text in text_ls\n",
    "        ]\n",
    "        \n",
    "        return token_nums\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        line_data = self.data.iloc[index]\n",
    "        text = line_data[\"process_text\"]\n",
    "        label = int(line_data[\"label\"])\n",
    "        token_nums = self.tokenize(text)\n",
    "        token_nums = torch.tensor(token_nums, dtype=torch.long)\n",
    "        \n",
    "        if self.for_test:\n",
    "            return token_nums\n",
    "        \n",
    "        return token_nums, torch.tensor([label], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2c52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,     \n",
    "        text_data:TextData,\n",
    "        process_all_data_output:dict, \n",
    "        batch_size:int=32, \n",
    "        num_workers:int=0, \n",
    "        pin_memory:bool=False,\n",
    "        val_ratio:float=0.1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.text_data = text_data  \n",
    "        self.key_to_index = text_data.model.wv.key_to_index\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        folder = Path(process_all_data_output[\"folder\"])\n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Folder {folder} does not exist.\")\n",
    "        \n",
    "        self.train_df_path = folder / process_all_data_output[\"train_path\"]\n",
    "        self.test_df_path = folder / process_all_data_output[\"test_path\"]\n",
    "        self.val_ratio = val_ratio\n",
    "        \n",
    "        return \n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_df = pd.read_csv(self.train_df_path)\n",
    "            \n",
    "            large_data = TextDataSet(train_df, key_to_index=self.key_to_index)\n",
    "            #TODO: split train and val dataset\n",
    "            total_size = len(large_data)\n",
    "            val_size = int(total_size * self.val_ratio)\n",
    "            train_size = total_size - val_size\n",
    "            \n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                large_data, [train_size, val_size]\n",
    "            )\n",
    "            \n",
    "            #TODO: build test dataset\n",
    "            self.predict_df = pd.read_csv(self.test_df_path)\n",
    "            self.predict_dataset = TextDataSet(self.predict_df, key_to_index=self.key_to_index, for_test=True)\n",
    "            \n",
    "            # get label\n",
    "            self.labels = natsorted(set(train_df[\"label\"].values))\n",
    "            self.number_of_classes = len(self.labels)\n",
    "            \n",
    "        \n",
    "        elif stage == \"predict\":\n",
    "            self.predict_df = pd.read_csv(self.test_df_path)\n",
    "            self.predict_dataset = TextDataSet(self.predict_df, key_to_index=self.key_to_index, for_test=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def detokenize(self, token_nums:list[int]) -> str:\n",
    "        # 使用 FastText 模型進行斷詞\n",
    "        index_to_key = list(self.key_to_index.keys())\n",
    "        text = \" \".join([\n",
    "            index_to_key[token_num]\n",
    "            for token_num in token_nums\n",
    "        ])\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def pad_collate(self, batch) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        inputs, targets = zip(*batch)\n",
    "\n",
    "        # 使用 PyTorch 的 pad_sequence 函数对输入进行填充\n",
    "        inputs = pad_sequence(\n",
    "            inputs, batch_first=True, padding_value=self.key_to_index[\"<PAD>\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "        return inputs, targets\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.pad_collate,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.pad_collate,\n",
    "        )\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.predict_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.pad_collate,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb47d2",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e768ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 若 d_model 為奇數，cos 會略少一個維度\n",
    "        if d_model % 2 == 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # shape: (1, max_len, d_model)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class EmbeddingConfig:\n",
    "    vocab_size: int\n",
    "    embed_dim: int\n",
    "\n",
    "    # fast_text_pretrained\n",
    "    state: bool = False\n",
    "    model_path: str = None\n",
    "    freeze: bool = False\n",
    "\n",
    "    @staticmethod\n",
    "    def config(vocab_size: int, embed_dim: int):\n",
    "        return EmbeddingConfig(vocab_size=vocab_size, embed_dim=embed_dim)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_embedding_pretrain(embedding_path: str, freeze: bool = True):\n",
    "        return EmbeddingConfig(\n",
    "            vocab_size=0,\n",
    "            embed_dim=0,\n",
    "            state=True,\n",
    "            model_path=embedding_path,\n",
    "            freeze=freeze,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def embedding_data(model: Word2Vec):\n",
    "        vocab = model.wv.index_to_key\n",
    "        vocab_size = len(vocab)\n",
    "        embed_dim = model.wv.vector_size\n",
    "        embedding_weight = torch.FloatTensor(\n",
    "            np.array([model.wv[word] for word in vocab])\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"vocab\": vocab,\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"embedding_weight\": embedding_weight,\n",
    "        }\n",
    "\n",
    "    def build_embedding_weight(self) -> torch.Tensor:\n",
    "\n",
    "        if not self.state:\n",
    "            raise ValueError(\n",
    "                \"EmbeddingConfig: fasttext pretrained embedding not found.\"\n",
    "            )\n",
    "\n",
    "        file_path = Path(self.model_path)\n",
    "        if not file_path.exists():\n",
    "            raise ValueError(\n",
    "                f\"EmbeddingConfig: fasttext pretrained embedding not found. {file_path}\"\n",
    "            )\n",
    "\n",
    "        model = FastText.load(str(file_path))\n",
    "        embedding_data = self.embedding_data(model)\n",
    "        self.vocab_size = embedding_data[\"vocab_size\"]\n",
    "        self.embed_dim = embedding_data[\"embed_dim\"]\n",
    "\n",
    "        return embedding_data[\"embedding_weight\"]\n",
    "\n",
    "\n",
    "class TransformerClassifier(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_dict: dict,\n",
    "        num_classes: int,\n",
    "        nhead: int = 8,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_length: int = 512,\n",
    "        ce_weights: list[float] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # vocab_size, embed_dim, embedding_weight = self.decode_config(config_dict)\n",
    "        config = EmbeddingConfig(**config_dict)\n",
    "        self.embedding, config = self.build_embedding(config)\n",
    "        self.embed_dim = config.embed_dim\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(self.embed_dim, dropout, max_seq_length)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # 可採用簡單的池化方式，例如取 [CLS] token 的輸出\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, self.embed_dim//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.embed_dim//2, num_classes),\n",
    "        )\n",
    "        \n",
    "        ce_weights = torch.tensor(ce_weights, dtype=torch.float) if ce_weights else None\n",
    "        \n",
    "        self.loss_func = nn.CrossEntropyLoss(ce_weights)\n",
    "        self.save_hyperparameters()\n",
    "        return\n",
    "\n",
    "    def build_embedding(self, config: EmbeddingConfig):\n",
    "\n",
    "        if not config.state:\n",
    "            return nn.Embedding(config.vocab_size, config.embed_dim), config\n",
    "\n",
    "        embedding_weight = config.build_embedding_weight()\n",
    "\n",
    "        return (\n",
    "            nn.Embedding.from_pretrained(embedding_weight, freeze=config.freeze),\n",
    "            config,\n",
    "        )\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: (batch_size, seq_len) --> token ids\n",
    "        x = self.embedding(src) * math.sqrt(\n",
    "            self.embed_dim\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        x = self.pos_encoder(x)\n",
    "        # TransformerEncoder 預設輸入 shape: (seq_len, batch_size, embed_dim)\n",
    "        # x = x.transpose(0, 1)\n",
    "        x = self.transformer_encoder(x)  # (seq_len, batch_size, embed_dim)\n",
    "        # 此處假設第一個 token 為 [CLS] token，可用於分類\n",
    "        # cls_token = x[0]  # shape: (batch_size, embed_dim)\n",
    "        # x = x[:, 0, :]  # shape: (batch_size, embed_dim)\n",
    "        x = x.mean(dim=1)  # shape: (batch_size, embed_dim)\n",
    "        logits = self.classifier(x)  # shape: (batch_size, num_classes)\n",
    "        return logits\n",
    "    \n",
    "    def loss_and_update_logs(self, pred: torch.Tensor, target: torch.Tensor, stage: str):\n",
    "        \n",
    "        loss = self.loss_func(pred, target)\n",
    "\n",
    "        acc = (torch.argmax(pred, dim=1) == target).float().mean()\n",
    "\n",
    "        self.log_dict({f\"{stage}_loss\": loss, f\"{stage}_acc\": acc})\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self,batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        logits = self(inputs)\n",
    "        \n",
    "        loss = self.loss_and_update_logs(logits, targets, \"train\")\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        logits = self(inputs)\n",
    "        \n",
    "        self.loss_and_update_logs(logits, targets, \"val\")\n",
    "        return \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),  lr=1e-3, weight_decay=1e-2)\n",
    "        total_steps = 100000\n",
    "        scheduler = CosineAnnealingLR(optimizer,T_max=total_steps, eta_min=1e-6)\n",
    "        return {\n",
    "            \"optimizer\": optimizer, \n",
    "            \"lr_scheduler\": scheduler\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_embedding_pretrained(\n",
    "        embedding_path: str,\n",
    "        num_classes: int,\n",
    "        feeze_pretrained_embedding: bool = True,\n",
    "        nhead: int = 8,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_length: int = 512,\n",
    "        ce_weights: list[float] = None,\n",
    "    ):\n",
    "        embedding_config = EmbeddingConfig.load_embedding_pretrain(\n",
    "            embedding_path, feeze_pretrained_embedding\n",
    "        )\n",
    "\n",
    "        return TransformerClassifier(\n",
    "            asdict(embedding_config),\n",
    "            num_classes=num_classes,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            max_seq_length=max_seq_length,\n",
    "            ce_weights=ce_weights,\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def build_model(\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_classes: int,\n",
    "        nhead: int = 8,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_length: int = 512,\n",
    "        ce_weights: list[float] = None,\n",
    "    ):\n",
    "        embedding_config = EmbeddingConfig.config(\n",
    "            vocab_size=vocab_size, embed_dim=embed_dim\n",
    "        )\n",
    "        return TransformerClassifier(\n",
    "            asdict(embedding_config),\n",
    "            num_classes=num_classes,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            max_seq_length=max_seq_length,\n",
    "            ce_weights=ce_weights,\n",
    "        )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ade99",
   "metadata": {},
   "source": [
    "## Build Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91515323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "MODEL_CONFIG = {\n",
    "    \"embedding_path\": str(EMBEDDING_MODEL_PATH),\n",
    "    \"num_classes\": 4,\n",
    "    \"feeze_pretrained_embedding\": True,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 2,\n",
    "    \"dim_feedforward\": 512,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"ce_weights\" : text_data.ce_weights(),\n",
    "}\n",
    "\n",
    "# data module\n",
    "DATA_CONFIG= {\n",
    "    \"text_data\": text_data,\n",
    "    \"process_all_data_output\": output,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 2,\n",
    "    \"pin_memory\": False,\n",
    "    \"val_ratio\": 0.15,\n",
    "}\n",
    "\n",
    "# training \n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "993cb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerClassifier.load_from_embedding_pretrained(**MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2f2461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerClassifier(\n",
      "  (embedding): Embedding(74602, 128)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      "  (loss_func): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a9ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dummy_input = torch.randint(0, 100, (2, 512))\n",
    "    print(dummy_input.shape)\n",
    "    dummy_output = model(dummy_input)\n",
    "    print(dummy_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7892f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data module\n",
    "datamodule = TextDataModule(**DATA_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f7caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(ALL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c99c9315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "csv_logger = CSVLogger(OUTPUT_PATH / \"logs\", name=f\"Norm_Transformers_ce\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    # dirpath=\"checkpoints\",\n",
    "    filename=\"model-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "trainer = L.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    logger=csv_logger,\n",
    "    max_epochs=EPOCHS,\n",
    "    fast_dev_run=True,\n",
    "    # log_every_n_steps=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aeb21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | embedding           | Embedding          | 9.5 M  | train\n",
      "1 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "2 | transformer_encoder | TransformerEncoder | 396 K  | train\n",
      "3 | classifier          | Sequential         | 8.5 K  | train\n",
      "4 | loss_func           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "405 K     Trainable params\n",
      "9.5 M     Non-trainable params\n",
      "10.0 M    Total params\n",
      "39.816    Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675e08760a3543df86abb1db52e57f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_batch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    322\u001b[39m         batch_output = \u001b[38;5;28mself\u001b[39m.manual_optimization.run(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         closure()\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_ready()\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_completed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    179\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimizer_step\u001b[39m(\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1273\u001b[39m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1276\u001b[39m     optimizer_closure: Optional[Callable[[], Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1277\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03m    the optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[33m\"\u001b[39m\u001b[33mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:140\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m opt = opt_ref()\n\u001b[32m    139\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/adamw.py:220\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n\u001b[32m    223\u001b[39m     params_with_grad: List[Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_closure\u001b[39m(\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     98\u001b[39m     model: \u001b[33m\"\u001b[39m\u001b[33mpl.LightningModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m     optimizer: Steppable,\n\u001b[32m    100\u001b[39m     closure: Callable[[], Any],\n\u001b[32m    101\u001b[39m ) -> Any:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    hook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m         \u001b[38;5;28mself\u001b[39m.warning_cache.warn(\u001b[33m\"\u001b[39m\u001b[33m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[32m    309\u001b[39m \n\u001b[32m    310\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    315\u001b[39m \n\u001b[32m    316\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer.world_size > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    331\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mTransformerClassifier.training_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    172\u001b[39m inputs, targets = batch\n\u001b[32m    173\u001b[39m logits = \u001b[38;5;28mself\u001b[39m(inputs)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_and_update_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 164\u001b[39m, in \u001b[36mTransformerClassifier.loss_and_update_logs\u001b[39m\u001b[34m(self, pred, target, stage)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_and_update_logs\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred: torch.Tensor, target: torch.Tensor, stage: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     acc = (torch.argmax(pred, dim=\u001b[32m1\u001b[39m) == target).float().mean()\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.log_dict({\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_loss\u001b[39m\u001b[33m\"\u001b[39m: loss, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_acc\u001b[39m\u001b[33m\"\u001b[39m: acc})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/nn/modules/loss.py:1295\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
